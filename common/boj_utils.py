"""
ë°±ì¤€ ê´€ë ¨ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
"""
import aiohttp
from bs4 import BeautifulSoup
import re
import os
import asyncio
from typing import List, Dict, Optional
from datetime import datetime, timedelta, timezone

# ë¡œê±° ê°€ì ¸ì˜¤ê¸°
try:
    from common.logger import get_logger
    logger = get_logger()
except ImportError:
    import logging
    logger = logging.getLogger(__name__)
    if not logger.handlers:
        handler = logging.StreamHandler()
        handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))
        logger.addHandler(handler)
        logger.setLevel(logging.INFO)

# solved.ac tier ë§¤í•‘ (ìˆ«ì -> ì´ë¦„)
TIER_MAPPING = {
    0: "Unrated",
    1: "Bronze V", 2: "Bronze IV", 3: "Bronze III", 4: "Bronze II", 5: "Bronze I",
    6: "Silver V", 7: "Silver IV", 8: "Silver III", 9: "Silver II", 10: "Silver I",
    11: "Gold V", 12: "Gold IV", 13: "Gold III", 14: "Gold II", 15: "Gold I",
    16: "Platinum V", 17: "Platinum IV", 18: "Platinum III", 19: "Platinum II", 20: "Platinum I",
    21: "Diamond V", 22: "Diamond IV", 23: "Diamond III", 24: "Diamond II", 25: "Diamond I",
    26: "Ruby V", 27: "Ruby IV", 28: "Ruby III", 29: "Ruby II", 30: "Ruby I",
}

def tier_to_number(tier_name: str) -> Optional[int]:
    """í‹°ì–´ ì´ë¦„ì„ ìˆ«ìë¡œ ë³€í™˜ (ì˜ˆ: "Gold II" -> 14, "G2" -> 14)"""
    # ì§§ì€ í˜•ì‹ ì²˜ë¦¬ (ì˜ˆ: "B5", "S1", "G2", "P3", "D4", "R5")
    if len(tier_name) == 2 and tier_name[0].isalpha() and tier_name[1].isdigit():
        tier_letter = tier_name[0].upper()
        level = int(tier_name[1])
        
        # í‹°ì–´ ë§¤í•‘
        tier_map = {
            'B': 'Bronze',
            'S': 'Silver',
            'G': 'Gold',
            'P': 'Platinum',
            'D': 'Diamond',
            'R': 'Ruby'
        }
        
        if tier_letter in tier_map:
            tier_base = tier_map[tier_letter]
            # ë ˆë²¨ì„ ë¡œë§ˆ ìˆ«ìë¡œ ë³€í™˜ (5=V, 4=IV, 3=III, 2=II, 1=I)
            level_map = {5: 'V', 4: 'IV', 3: 'III', 2: 'II', 1: 'I'}
            tier_full = f"{tier_base} {level_map.get(level, '')}"
            
            for num, name in TIER_MAPPING.items():
                if name == tier_full:
                    return num
    
    # ê¸°ì¡´ í˜•ì‹ ì²˜ë¦¬ (ì˜ˆ: "Gold II")
    for num, name in TIER_MAPPING.items():
        if name == tier_name:
            return num
    return None

def number_to_tier(tier_num: int) -> str:
    """ìˆ«ìë¥¼ í‹°ì–´ ì´ë¦„ìœ¼ë¡œ ë³€í™˜ (ì˜ˆ: 14 -> "Gold II")"""
    return TIER_MAPPING.get(tier_num, "Unknown")

def number_to_tier_short(tier_num: int) -> str:
    """ìˆ«ìë¥¼ ì§§ì€ í‹°ì–´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (ì˜ˆ: 14 -> "G2", 1 -> "B5")
    
    í˜•ì‹: í‹°ì–´ ì•ê¸€ì + ë‚œì´ë„ ìˆ«ì
    - Bronze V~I -> B5~B1
    - Silver V~I -> S5~S1
    - Gold V~I -> G5~G1
    - Platinum V~I -> P5~P1
    - Diamond V~I -> D5~D1
    - Ruby V~I -> R5~R1
    """
    if tier_num == 0:
        return "Unrated"
    
    tier_name = TIER_MAPPING.get(tier_num, "Unknown")
    if tier_name == "Unknown":
        return "Unknown"
    
    # í‹°ì–´ ì•ê¸€ì ì¶”ì¶œ
    tier_letter = tier_name[0]
    
    # ë‚œì´ë„ ìˆ«ì ê³„ì‚° (V=5, IV=4, III=3, II=2, I=1)
    if "V" in tier_name:
        level = 5
    elif "IV" in tier_name:
        level = 4
    elif "III" in tier_name:
        level = 3
    elif "II" in tier_name:
        level = 2
    elif "I" in tier_name:
        level = 1
    else:
        return tier_name
    
    return f"{tier_letter}{level}"

async def get_problem_tier(problem_id: int) -> Optional[int]:
    """ë¬¸ì œì˜ í‹°ì–´ ì •ë³´ ê°€ì ¸ì˜¤ê¸° (solved.ac)"""
    try:
        url = f"https://solved.ac/api/v3/problem/show?problemId={problem_id}"
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        
        async with aiohttp.ClientSession(headers=headers) as session:
            async with session.get(url) as response:
                if response.status == 200:
                    data = await response.json()
                    level = data.get('level', 0)
                    return level
        return None
    except Exception as e:
        print(f"í‹°ì–´ ì •ë³´ ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜: {e}")
        return None

async def get_user_solved_problems(baekjoon_id: str, start_date: datetime = None) -> List[int]:
    """ì‚¬ìš©ìê°€ í•´ê²°í•œ ë¬¸ì œ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° (ë‚ ì§œ í•„í„°ë§ ê°€ëŠ¥)"""
    try:
        url = f"https://www.acmicpc.net/user/{baekjoon_id}"
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        
        async with aiohttp.ClientSession(headers=headers) as session:
            async with session.get(url) as response:
                if response.status != 200:
                    return []
                
                html = await response.text()
                soup = BeautifulSoup(html, 'html.parser')
                
                # í•´ê²°í•œ ë¬¸ì œ ëª©ë¡ ì¶”ì¶œ
                solved_problems = []
                problem_panels = soup.find_all('div', class_='problem-list')
                
                for panel in problem_panels:
                    problem_links = panel.find_all('a', href=re.compile(r'/problem/\d+'))
                    for link in problem_links:
                        problem_id = int(re.search(r'/problem/(\d+)', link['href']).group(1))
                        solved_problems.append(problem_id)
                
                # ë‚ ì§œ í•„í„°ë§ì´ í•„ìš”í•œ ê²½ìš° (ì¶”í›„ êµ¬í˜„)
                # í˜„ì¬ëŠ” ì „ì²´ ëª©ë¡ ë°˜í™˜
                return solved_problems
    except Exception as e:
        print(f"í•´ê²°í•œ ë¬¸ì œ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜: {e}")
        return []

async def get_user_solved_problems_from_solved_ac(baekjoon_id: str, target_problems: List[int] = None) -> List[int]:
    """
    solved.acì—ì„œ ì‚¬ìš©ìê°€ í•´ê²°í•œ ë¬¸ì œ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    
    Args:
        baekjoon_id: ë°±ì¤€ ì•„ì´ë””
        target_problems: í™•ì¸í•  ë¬¸ì œ ë²ˆí˜¸ ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ ì „ì²´ ê°€ì ¸ì˜¤ê¸°)
                        ì´ ë¦¬ìŠ¤íŠ¸ê°€ ì œê³µë˜ë©´ ë¬¸ì œ ê²€ìƒ‰ APIë¥¼ ì‚¬ìš©í•˜ì—¬ íš¨ìœ¨ì ìœ¼ë¡œ í™•ì¸
    
    Returns:
        í•´ê²°í•œ ë¬¸ì œ ë²ˆí˜¸ ë¦¬ìŠ¤íŠ¸
    """
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7',
        }
        
        # target_problemsê°€ ì œê³µë˜ë©´ ë¬¸ì œ ê²€ìƒ‰ API ì‚¬ìš© (ë” íš¨ìœ¨ì )
        # ì˜ˆ: https://solved.ac/problems?query=s%40beans3142+1000%7C1001%7C1002
        if target_problems and len(target_problems) <= 50:  # URL ê¸¸ì´ ì œí•œ ê³ ë ¤
            return await _check_problems_via_search_api(baekjoon_id, target_problems, headers)
        
        # ì „ì²´ ëª©ë¡ì´ í•„ìš”í•˜ê±°ë‚˜ ë¬¸ì œê°€ ë§ìœ¼ë©´ í˜ì´ì§€ í¬ë¡¤ë§ ì‚¬ìš©
        return await _get_all_solved_problems_via_pages(baekjoon_id, target_problems, headers)
                
    except Exception as e:
        logger.error(f"[solved.ac í¬ë¡¤ë§] ì˜¤ë¥˜: {e}", exc_info=True)
        return []


async def _check_problems_via_search_api(baekjoon_id: str, target_problems: List[int], headers: dict) -> List[int]:
    """
    solved.ac ë¬¸ì œ ê²€ìƒ‰ APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ìê°€ í‘¼ ëª¨ë“  ë¬¸ì œë¥¼ í˜ì´ì§€ë„¤ì´ì…˜ìœ¼ë¡œ í™•ì¸
    https://solved.ac/problems?query=s@{handle}&page=1
    
    ê° í˜ì´ì§€ì—ì„œ ë¬¸ì œ ë²ˆí˜¸ë¥¼ ì¶”ì¶œí•˜ê³ , target_problemsì— ìˆëŠ” ë¬¸ì œë§Œ í•„í„°ë§í•˜ì—¬ ë°˜í™˜
    """
    try:
        import urllib.parse
        
        # ì‚¬ìš©ìê°€ í‘¼ ëª¨ë“  ë¬¸ì œ ê²€ìƒ‰ (ë¬¸ì œ ë²ˆí˜¸ í•„í„° ì—†ì´)
        query = f"s@{baekjoon_id}"
        encoded_query = urllib.parse.quote(query)
        
        target_set = set(target_problems)
        solved_problems = []
        page = 1
        max_pages = 100  # ìµœëŒ€ 100í˜ì´ì§€
        last_page = None  # ë§ˆì§€ë§‰ í˜ì´ì§€ ë²ˆí˜¸
        
        async with aiohttp.ClientSession(headers=headers) as session:
            while page <= max_pages:
                url = f"https://solved.ac/problems?query={encoded_query}&page={page}"
                
                async with session.get(url) as response:
                    if response.status != 200:
                        if page == 1:
                            logger.warning(f"[solved.ac ê²€ìƒ‰ API] HTTP {response.status} ì—ëŸ¬: {url}")
                            return []
                        # ì²« í˜ì´ì§€ê°€ ì•„ë‹ˆë©´ ë” ì´ìƒ í˜ì´ì§€ê°€ ì—†ëŠ” ê²ƒìœ¼ë¡œ ê°„ì£¼
                        break
                    
                    html = await response.text()
                    soup = BeautifulSoup(html, 'html.parser')
                    
                    # ì²« í˜ì´ì§€ì—ì„œ ë§ˆì§€ë§‰ í˜ì´ì§€ ë²ˆí˜¸ íŒŒì‹±
                    if page == 1 and last_page is None:
                        # í˜ì´ì§€ë„¤ì´ì…˜ ë²„íŠ¼ì—ì„œ ë§ˆì§€ë§‰ í˜ì´ì§€ ë²ˆí˜¸ ì°¾ê¸°
                        # ì˜ˆ: <a role="button" href="/problems?query=...&page=42">42</a>
                        pagination_links = soup.find_all('a', href=re.compile(r'[?&]page=\d+'))
                        page_numbers = []
                        for link in pagination_links:
                            href = link.get('href', '')
                            match = re.search(r'[?&]page=(\d+)', href)
                            if match:
                                page_num = int(match.group(1))
                                page_numbers.append(page_num)
                        
                        if page_numbers:
                            last_page = max(page_numbers)
                            logger.info(f"[solved.ac ê²€ìƒ‰ API] {baekjoon_id} - ì´ {last_page}í˜ì´ì§€ ë°œê²¬")
                            # max_pagesë¥¼ last_pageë¡œ ì œí•œ
                            max_pages = min(max_pages, last_page)
                    
                    # í˜ì´ì§€ì—ì„œ ë¬¸ì œ ë²ˆí˜¸ ì¶”ì¶œ
                    page_problems = []
                    problem_links = soup.find_all('a', href=re.compile(r'(?:acmicpc\.net/problem/|/problem/)\d+'))
                    
                    for link in problem_links:
                        href = link.get('href', '')
                        # ì „ì²´ URL ë˜ëŠ” ìƒëŒ€ ê²½ë¡œì—ì„œ ë¬¸ì œ ë²ˆí˜¸ ì¶”ì¶œ
                        match = re.search(r'(?:acmicpc\.net/problem/|/problem/)(\d+)', href)
                        if match:
                            problem_id = int(match.group(1))
                            page_problems.append(problem_id)
                    
                    if not page_problems:
                        # í˜ì´ì§€ì— ë¬¸ì œê°€ ì—†ìœ¼ë©´ ë” ì´ìƒ í˜ì´ì§€ê°€ ì—†ëŠ” ê²ƒìœ¼ë¡œ ê°„ì£¼
                        break
                    
                    # target_problemsì— ìˆëŠ” ë¬¸ì œë§Œ í•„í„°ë§
                    for problem_id in page_problems:
                        if problem_id in target_set:
                            solved_problems.append(problem_id)
                    
                    # ëª¨ë“  ëª©í‘œ ë¬¸ì œë¥¼ ì°¾ì•˜ìœ¼ë©´ ì¡°ê¸° ì¢…ë£Œ
                    found_set = set(solved_problems)
                    if len(found_set) == len(target_set):
                        logger.info(f"[solved.ac ê²€ìƒ‰ API] {baekjoon_id} - ëª©í‘œ ë¬¸ì œ {len(target_set)}ê°œë¥¼ ëª¨ë‘ ì°¾ì•„ ì¡°ê¸° ì¢…ë£Œ (í˜ì´ì§€ {page}/{last_page or '?'})")
                        break
                    
                    # ë§ˆì§€ë§‰ í˜ì´ì§€ì— ë„ë‹¬í–ˆìœ¼ë©´ ì¢…ë£Œ
                    if last_page and page >= last_page:
                        break
                    
                    page += 1
                    await asyncio.sleep(0.3)  # Rate limiting ë°©ì§€
                
                # ì¤‘ë³µ ì œê±° ë° ì •ë ¬
                solved_problems = sorted(list(set(solved_problems)))
                
                logger.info(f"[solved.ac ê²€ìƒ‰ API] {baekjoon_id} - ëª©í‘œ ë¬¸ì œ ì¤‘ {len(solved_problems)}/{len(target_problems)}ê°œ í•´ê²° (í˜ì´ì§€ {page-1}ê°œ í¬ë¡¤ë§)")
                return solved_problems
                
    except Exception as e:
        logger.error(f"[solved.ac ê²€ìƒ‰ API] ì˜¤ë¥˜: {e}", exc_info=True)
        return []


async def _get_all_solved_problems_via_pages(baekjoon_id: str, target_problems: List[int] = None, headers: dict = None) -> List[int]:
    """
    solved.ac profile í˜ì´ì§€ë¥¼ í¬ë¡¤ë§í•˜ì—¬ ì „ì²´ í•´ê²°í•œ ë¬¸ì œ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    """
    if headers is None:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7',
        }
    
    solved_problems = []
    page = 1
    max_pages = 100  # ìµœëŒ€ 100í˜ì´ì§€ (ì•½ 5000ê°œ ë¬¸ì œ)
    target_set = set(target_problems) if target_problems else None
    last_page = None  # ë§ˆì§€ë§‰ í˜ì´ì§€ ë²ˆí˜¸
    
    async with aiohttp.ClientSession(headers=headers) as session:
        while page <= max_pages:
            url = f"https://solved.ac/profile/{baekjoon_id}/solved"
            if page > 1:
                url += f"?page={page}"
            
            async with session.get(url) as response:
                if response.status != 200:
                    if page == 1:
                        logger.warning(f"[solved.ac í¬ë¡¤ë§] HTTP {response.status} ì—ëŸ¬: {url}")
                        return []
                    # ì²« í˜ì´ì§€ê°€ ì•„ë‹ˆë©´ ë” ì´ìƒ í˜ì´ì§€ê°€ ì—†ëŠ” ê²ƒìœ¼ë¡œ ê°„ì£¼
                    break
                
                html = await response.text()
                soup = BeautifulSoup(html, 'html.parser')
                
                # ì²« í˜ì´ì§€ì—ì„œ ë§ˆì§€ë§‰ í˜ì´ì§€ ë²ˆí˜¸ íŒŒì‹±
                if page == 1 and last_page is None:
                    # í˜ì´ì§€ë„¤ì´ì…˜ ë²„íŠ¼ì—ì„œ ë§ˆì§€ë§‰ í˜ì´ì§€ ë²ˆí˜¸ ì°¾ê¸°
                    # ì˜ˆ: <a role="button" href="/profile/beans3142/solved?page=42" class="css-13gyek6">42</a>
                    pagination_links = soup.find_all('a', href=re.compile(r'/profile/[^/]+/solved\?page=\d+'))
                    page_numbers = []
                    for link in pagination_links:
                        href = link.get('href', '')
                        match = re.search(r'page=(\d+)', href)
                        if match:
                            page_num = int(match.group(1))
                            page_numbers.append(page_num)
                    
                    if page_numbers:
                        last_page = max(page_numbers)
                        logger.info(f"[solved.ac í¬ë¡¤ë§] {baekjoon_id} - ì´ {last_page}í˜ì´ì§€ ë°œê²¬")
                        # max_pagesë¥¼ last_pageë¡œ ì œí•œ
                        max_pages = min(max_pages, last_page)
                
                # ë¬¸ì œ ë²ˆí˜¸ ì¶”ì¶œ (í…Œì´ë¸”ì—ì„œ)
                page_problems = []
                problem_links = soup.find_all('a', href=re.compile(r'/problem/\d+'))
                
                for link in problem_links:
                    href = link.get('href', '')
                    match = re.search(r'/problem/(\d+)', href)
                    if match:
                        problem_id = int(match.group(1))
                        page_problems.append(problem_id)
                
                if not page_problems:
                    # í˜ì´ì§€ì— ë¬¸ì œê°€ ì—†ìœ¼ë©´ ë” ì´ìƒ í˜ì´ì§€ê°€ ì—†ëŠ” ê²ƒìœ¼ë¡œ ê°„ì£¼
                    break
                
                solved_problems.extend(page_problems)
                
                # target_problemsê°€ ì œê³µë˜ê³ , ëª¨ë“  ë¬¸ì œë¥¼ ì°¾ì•˜ìœ¼ë©´ ì¡°ê¸° ì¢…ë£Œ
                if target_set:
                    found_problems = set(solved_problems) & target_set
                    if len(found_problems) == len(target_set):
                        logger.info(f"[solved.ac í¬ë¡¤ë§] {baekjoon_id} - ëª©í‘œ ë¬¸ì œ {len(target_set)}ê°œë¥¼ ëª¨ë‘ ì°¾ì•„ ì¡°ê¸° ì¢…ë£Œ (í˜ì´ì§€ {page}/{last_page or '?'})")
                        # ëª©í‘œ ë¬¸ì œë§Œ ë°˜í™˜
                        return sorted(list(found_problems))
                
                # ë§ˆì§€ë§‰ í˜ì´ì§€ì— ë„ë‹¬í–ˆìœ¼ë©´ ì¢…ë£Œ
                if last_page and page >= last_page:
                    break
                
                page += 1
                await asyncio.sleep(0.3)  # Rate limiting ë°©ì§€
    
    # ì¤‘ë³µ ì œê±° ë° ì •ë ¬
    solved_problems = sorted(list(set(solved_problems)))
    
    # target_problemsê°€ ì œê³µë˜ì—ˆìœ¼ë©´ í•´ë‹¹ ë¬¸ì œë§Œ í•„í„°ë§í•˜ì—¬ ë°˜í™˜
    if target_set:
        solved_problems = sorted(list(set(solved_problems) & target_set))
        logger.info(f"[solved.ac í¬ë¡¤ë§] {baekjoon_id} - ëª©í‘œ ë¬¸ì œ ì¤‘ {len(solved_problems)}/{len(target_set)}ê°œ í•´ê²° (í˜ì´ì§€ {page-1}ê°œ í¬ë¡¤ë§)")
    else:
        logger.info(f"[solved.ac í¬ë¡¤ë§] {baekjoon_id} - í•´ê²°í•œ ë¬¸ì œ {len(solved_problems)}ê°œ ë°œê²¬ (í˜ì´ì§€ {page-1}ê°œ í¬ë¡¤ë§)")
    
    return solved_problems

async def verify_user_exists(baekjoon_id: str) -> bool:
    """
    ë°±ì¤€(BOJ) ì‚¬ìš©ì ì¡´ì¬ ì—¬ë¶€ í™•ì¸

    ê¸°ì¡´ì—ëŠ” acmicpc.net í”„ë¡œí•„ í˜ì´ì§€(HTML)ë¥¼ ì§ì ‘ ì¡°íšŒí–ˆì§€ë§Œ,
    í˜„ì¬ ì„œë²„ IPê°€ BOJ ìª½ì—ì„œ 403ìœ¼ë¡œ ì°¨ë‹¨ëœ ìƒíƒœë¼ solved.ac APIë¡œ ëŒ€ì²´í•œë‹¤.

    solved.ac ë¬¸ì„œ ê¸°ì¤€:
      - GET /api/v3/user/show?handle={handle}
      - 200: ì‚¬ìš©ì ì¡´ì¬
      - 404: ì‚¬ìš©ì ì—†ìŒ
    """
    try:
        url = f"https://solved.ac/api/v3/user/show?handle={baekjoon_id}"
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }

        async with aiohttp.ClientSession(headers=headers) as session:
            async with session.get(url) as response:
                if response.status == 200:
                    return True
                if response.status == 404:
                    return False
                # ê¸°íƒ€ ìƒíƒœì½”ë“œëŠ” ë³´ìˆ˜ì ìœ¼ë¡œ False ì²˜ë¦¬
                return False
    except Exception as e:
        print(f"solved.ac ì‚¬ìš©ì í™•ì¸ ì˜¤ë¥˜: {e}")
        return False

async def check_problem_solved(baekjoon_id: str, problem_id: int) -> bool:
    """íŠ¹ì • ë¬¸ì œë¥¼ í•´ê²°í–ˆëŠ”ì§€ í™•ì¸ (status í˜ì´ì§€ì—ì„œ í™•ì¸)"""
    result = await check_problem_solved_from_status(baekjoon_id, problem_id)
    return result['solved'] if result else False

async def get_weekly_solved_count(baekjoon_id: str, start_date: datetime, end_date: datetime) -> Dict:
    """
    íŠ¹ì • ê¸°ê°„ ë™ì•ˆ í•´ê²°í•œ ë¬¸ì œ ìˆ˜ ë° ë¬¸ì œ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°

    ê¸°ì¡´ êµ¬í˜„ì€ BOJ status í˜ì´ì§€(HTML)ë¥¼ ì—¬ëŸ¬ í˜ì´ì§€ í¬ë¡¤ë§í–ˆì§€ë§Œ,
    í˜„ì¬ ì„œë²„ IPê°€ BOJì—ì„œ 403ì´ê¸° ë•Œë¬¸ì— solved.acì˜ user history APIë¡œ ëŒ€ì²´í•œë‹¤.

    solved.ac history API:
      - GET /api/v3/user/history?handle={handle}&topic=solvedCount
      - ì‘ë‹µ: ë‚ ì§œë³„ ëˆ„ì  solvedCount ëª©ë¡
        ì˜ˆì‹œ: [{ "date": "2025-12-30", "value": 2044 }, ...]

    ëˆ„ì  ê°’ì´ë¯€ë¡œ,
      ê¸°ê°„ [start, end] ì— í‘¼ ë¬¸ì œ ìˆ˜ = value(end) - value(start - 1ì¼)
    ìœ¼ë¡œ ê³„ì‚°í•œë‹¤.
    """
    try:
        url = f"https://solved.ac/api/v3/user/history?handle={baekjoon_id}&topic=solvedCount"
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }

        async with aiohttp.ClientSession(headers=headers) as session:
            async with session.get(url) as response:
                if response.status != 200:
                    return {'count': 0, 'problems': []}

                data = await response.json()

        # solved.ac history API ì‘ë‹µ í˜•ì‹:
        # [{"timestamp": "2021-09-12T04:37:27.000Z", "value": 445}, ...]
        # timestampëŠ” ISO 8601(UTC) í˜•ì‹ì´ë©°, ê°™ì€ ë‚ ì— ì—¬ëŸ¬ í•­ëª©ì´ ìˆì„ ìˆ˜ ìˆë‹¤.
        # ì—¬ê¸°ì„œëŠ” ì‹œê° ë‹¨ìœ„ ëˆ„ì ê°’ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•´ ì£¼ì–´ì§„ ì‹œê° ë²”ìœ„ë¡œ ì •í™•íˆ ì˜ë¼ë‚¸ë‹¤.
        history = []  # [(dt_utc, value)]
        for entry in data:
            timestamp_str = entry.get('timestamp')
            value = entry.get('value')
            if not timestamp_str or value is None:
                continue
            try:
                # "2021-09-12T04:37:27.000Z" í˜•ì‹ â†’ UTC naive datetime
                dt = datetime.fromisoformat(
                    timestamp_str.replace("Z", "+00:00")
                ).replace(tzinfo=None)
                v = int(value)
                history.append((dt, v))
            except Exception:
                continue

        if not history:
            return {'count': 0, 'problems': []}

        # ì‹œê° ìˆœ ì •ë ¬
        history.sort(key=lambda x: x[0])

        # channel.py ì—ì„œëŠ” KST(UTC+9) ê¸°ì¤€ start/end ë¥¼ ë„˜ê¸°ë¯€ë¡œ,
        # ë¹„êµë¥¼ ìœ„í•´ UTC ë¡œ ë³€í™˜í•´ì„œ ì‚¬ìš©í•œë‹¤.
        def to_utc(dt: datetime) -> datetime:
            if dt.tzinfo is not None:
                # timezone-awareë©´ UTCë¡œ ë³€í™˜
                return dt.astimezone(timezone.utc).replace(tzinfo=None)
            else:
                # timezone-naiveë©´ 9ì‹œê°„ ë¹¼ê¸° (KST â†’ UTC)
                return dt - timedelta(hours=9)

        start_utc = to_utc(start_date)
        end_utc = to_utc(end_date)

        def cumulative_before(target_dt: datetime, inclusive: bool) -> int:
            """
            target_dt ì´ì „(ë˜ëŠ” ì´í•˜)ê¹Œì§€ì˜ ëˆ„ì  solvedCount.
            history ëŠ” ì‹œê°„ ì¦ê°€ì— ë”°ë¼ value ê°€ ì¦ê°€/ìœ ì§€ë˜ëŠ” ëˆ„ì ê°’ ì‹œê³„ì—´ì´ë¼ê³  ê°€ì •.
            """
            last_val = 0
            for dt, v in history:
                if dt < target_dt or (inclusive and dt <= target_dt):
                    last_val = v
                else:
                    break
            return last_val

        # ì‹œì‘ ì‹œê° ì§ì „ê¹Œì§€ì˜ ëˆ„ì ê³¼ ì¢…ë£Œ ì‹œê°ê¹Œì§€ì˜ ëˆ„ì  ì°¨ì´ë¡œ ê¸°ê°„ ë‚´ í’€ì´ ìˆ˜ ê³„ì‚°
        total_before = cumulative_before(start_utc, inclusive=False)
        total_end = cumulative_before(end_utc, inclusive=True)

        count = max(0, total_end - total_before)

        # solved.ac historyë¡œëŠ” ê°œë³„ ë¬¸ì œ ë²ˆí˜¸ê¹Œì§€ëŠ” ì•Œ ìˆ˜ ì—†ìœ¼ë¯€ë¡œ,
        # countë§Œ ì±„ìš°ê³  problems ë¦¬ìŠ¤íŠ¸ëŠ” ë¹„ì›Œë‘”ë‹¤.
        return {
            'count': count,
            'problems': []
        }
    except Exception as e:
        print(f"ì£¼ê°„ í•´ê²°í•œ ë¬¸ì œ ìˆ˜ ì¡°íšŒ ì˜¤ë¥˜(solved.ac): {e}")
        return {'count': 0, 'problems': []}

async def get_weekly_solved_from_boj_status(baekjoon_id: str, start_date: datetime, end_date: datetime, status_callback=None) -> Dict:
    """
    ë°±ì¤€ status í˜ì´ì§€ì—ì„œ ì§ì ‘ í¬ë¡¤ë§í•˜ì—¬ íŠ¹ì • ê¸°ê°„ ë™ì•ˆ í•´ê²°í•œ ë¬¸ì œ ìˆ˜ ë° ë¬¸ì œ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    
    URL íŒ¨í„´: https://www.acmicpc.net/status?user_id={baekjoon_id}&result_id=4&top={top}
    top íŒŒë¼ë¯¸í„°ëŠ” ì œì¶œ IDë¥¼ ì‚¬ìš©í•˜ì—¬ í˜ì´ì§€ë„¤ì´ì…˜ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    
    ì£¼ì˜: í´ë¼ìš°ë“œ í™˜ê²½ì—ì„œ 403 FORBIDDENì´ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    ì´ ê²½ìš° solved.ac APIë¡œ ìë™ í´ë°±í•©ë‹ˆë‹¤.
    
    Args:
        baekjoon_id: ë°±ì¤€ ì•„ì´ë””
        start_date: ì‹œì‘ ë‚ ì§œ (datetime)
        end_date: ì¢…ë£Œ ë‚ ì§œ (datetime)
        status_callback: ìƒíƒœ ë©”ì‹œì§€ë¥¼ ë³´ë‚¼ ì½œë°± í•¨ìˆ˜ (async function(message: str))
    
    Returns:
        {'count': int, 'problems': List[int]}
    """
    try:
        solved_problems = set()
        # ë” ì •êµí•œ í—¤ë” ì„¤ì • (403 ìš°íšŒ ì‹œë„)
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8',
            'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'none',
            'Sec-Fetch-User': '?1',
            'Referer': 'https://www.acmicpc.net/',
        }
        
        import asyncio
        
        async with aiohttp.ClientSession(headers=headers) as session:
            # ì²« í˜ì´ì§€ëŠ” top íŒŒë¼ë¯¸í„° ì—†ì´ ì‹œì‘
            top = None
            max_pages = 50  # ìµœëŒ€ 50í˜ì´ì§€ê¹Œì§€ í™•ì¸ (ì•½ 5000ê°œ ì œì¶œ)
            page_count = 0
            
            while page_count < max_pages:
                # result_id=4ëŠ” "ë§ì•˜ìŠµë‹ˆë‹¤" ê²°ê³¼
                if top is None:
                    url = f"https://www.acmicpc.net/status?user_id={baekjoon_id}&result_id=4"
                else:
                    url = f"https://www.acmicpc.net/status?user_id={baekjoon_id}&result_id=4&top={top}"
                
                async with session.get(url) as response:
                    # 403 FORBIDDEN ì—ëŸ¬ ì²˜ë¦¬
                    if response.status == 403:
                        status_msg = "âŒ 403 FORBIDDEN ì—ëŸ¬ ë°œìƒ - IP ì°¨ë‹¨ ê°€ëŠ¥ì„±"
                        logger.warning(f"[ë°±ì¤€ í¬ë¡¤ë§] 403 FORBIDDEN ì—ëŸ¬ ë°œìƒ - IP ì°¨ë‹¨ ê°€ëŠ¥ì„±")
                        if status_callback:
                            await status_callback(status_msg)
                        
                        # ì²« ë²ˆì§¸ ìš”ì²­ì—ì„œ 403ì´ë©´ ì „ì²´ ì‹¤íŒ¨ë¡œ ì²˜ë¦¬
                        if page_count == 0:
                            status_msg = "ğŸ”„ solved.ac APIë¡œ í´ë°± ì‹œë„..."
                            logger.info(f"[ë°±ì¤€ í¬ë¡¤ë§] solved.ac APIë¡œ í´ë°± ì‹œë„...")
                            if status_callback:
                                await status_callback(status_msg)
                            # solved.acë¡œ í´ë°± (ë¬¸ì œ ë²ˆí˜¸ëŠ” ì—†ì§€ë§Œ ê°œìˆ˜ëŠ” ì•Œ ìˆ˜ ìˆìŒ)
                            fallback_result = await get_weekly_solved_count(baekjoon_id, start_date, end_date)
                            return fallback_result
                        break
                    
                    if response.status != 200:
                        print(f"[ë°±ì¤€ í¬ë¡¤ë§] HTTP {response.status} ì—ëŸ¬")
                        break
                    
                    html = await response.text()
                    
                    # AWS WAF ì±Œë¦°ì§€ í˜ì´ì§€ í™•ì¸
                    if 'awsWafCookieDomainList' in html or 'gokuProps' in html:
                        print(f"[ë°±ì¤€ í¬ë¡¤ë§] AWS WAF ì±Œë¦°ì§€ í˜ì´ì§€ ê°ì§€")
                        if page_count == 0:
                            # ì²« í˜ì´ì§€ì—ì„œ WAF ê°ì§€ë˜ë©´ í´ë°±
                            print(f"[ë°±ì¤€ í¬ë¡¤ë§] solved.ac APIë¡œ í´ë°± ì‹œë„...")
                            fallback_result = await get_weekly_solved_count(baekjoon_id, start_date, end_date)
                            return fallback_result
                        await asyncio.sleep(5)  # WAF ì±Œë¦°ì§€ ëŒ€ê¸°
                        continue
                    
                    soup = BeautifulSoup(html, 'html.parser')
                    
                    # status í…Œì´ë¸” ì°¾ê¸°
                    status_table = soup.find('table', id='status-table')
                    if not status_table:
                        break
                    
                    tbody = status_table.find('tbody')
                    if not tbody:
                        break
                    
                    rows = tbody.find_all('tr')
                    if not rows:
                        break
                    
                    # ì´ í˜ì´ì§€ì˜ ëª¨ë“  ì œì¶œì´ ê¸°ê°„ì„ ë²—ì–´ë‚˜ë©´ ì¤‘ë‹¨
                    page_has_valid = False
                    last_submission_id = None
                    
                    for tr in rows:
                        # ì œì¶œ ID ì°¾ê¸° (ë‹¤ìŒ í˜ì´ì§€ë¥¼ ìœ„í•œ top ê°’)
                        # ë°±ì¤€ status í˜ì´ì§€ì—ì„œ ì²« ë²ˆì§¸ tdê°€ ì œì¶œ ë²ˆí˜¸ì…ë‹ˆë‹¤
                        tds = tr.find_all('td')
                        if tds and len(tds) > 0:
                            try:
                                # ì²« ë²ˆì§¸ tdì˜ í…ìŠ¤íŠ¸ê°€ ì œì¶œ ë²ˆí˜¸
                                submission_id = int(tds[0].get_text(strip=True))
                                if last_submission_id is None or submission_id < last_submission_id:
                                    last_submission_id = submission_id
                            except:
                                pass
                        
                        # ê²°ê³¼ í™•ì¸
                        result_td = tr.find('td', class_='result')
                        if not result_td:
                            continue
                        
                        result_text = result_td.get_text(strip=True)
                        if 'ë§ì•˜ìŠµë‹ˆë‹¤' not in result_text:
                            continue
                        
                        # ì œì¶œ ì‹œê°„ ì°¾ê¸°
                        time_td = tr.find('td', class_='real-time-update')
                        if not time_td:
                            time_elem = tr.find('a', class_='real-time-update')
                            if time_elem and time_elem.get('title'):
                                time_str = time_elem.get('title')
                            else:
                                continue
                        else:
                            time_str = time_td.get_text(strip=True)
                        
                        # ì‹œê°„ íŒŒì‹±
                        try:
                            if '-' in time_str and ':' in time_str:
                                # "2024-01-01 12:34:56" í˜•ì‹
                                submitted_dt = datetime.strptime(time_str, '%Y-%m-%d %H:%M:%S')
                            else:
                                # ìƒëŒ€ ì‹œê°„ì¸ ê²½ìš° í˜„ì¬ ì‹œê°„ ì‚¬ìš© (ì •í™•í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ)
                                continue
                        except:
                            continue
                        
                        # ê¸°ê°„ í™•ì¸
                        if start_date <= submitted_dt <= end_date:
                            # ë¬¸ì œ ë²ˆí˜¸ ì°¾ê¸°
                            problem_link = tr.find('a', href=re.compile(r'/problem/\d+'))
                            if problem_link:
                                match = re.search(r'/problem/(\d+)', problem_link.get('href', ''))
                                if match:
                                    problem_id = int(match.group(1))
                                    solved_problems.add(problem_id)
                                    page_has_valid = True
                        elif submitted_dt < start_date:
                            # ì‹œì‘ ë‚ ì§œë³´ë‹¤ ì´ì „ì´ë©´ ë” ì´ìƒ í™•ì¸í•  í•„ìš” ì—†ìŒ
                            # (í˜ì´ì§€ëŠ” ìµœì‹ ìˆœì´ë¯€ë¡œ)
                            return {
                                'count': len(solved_problems),
                                'problems': sorted(list(solved_problems))
                            }
                    
                    # ë‹¤ìŒ í˜ì´ì§€ë¥¼ ìœ„í•œ top ê°’ ì„¤ì •
                    if last_submission_id is not None:
                        top = last_submission_id
                    else:
                        # submission_idë¥¼ ì°¾ì„ ìˆ˜ ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ í–‰ì˜ ì œì¶œ ë²ˆí˜¸ë¥¼ ì‚¬ìš©
                        if rows:
                            first_row = rows[0]
                            first_tds = first_row.find_all('td')
                            if first_tds and len(first_tds) > 0:
                                try:
                                    top = int(first_tds[0].get_text(strip=True))
                                except:
                                    break
                            else:
                                break
                        else:
                            break
                    
                    # ì´ í˜ì´ì§€ì— ìœ íš¨í•œ ì œì¶œì´ ì—†ìœ¼ë©´ ë” ì´ìƒ í™•ì¸í•˜ì§€ ì•ŠìŒ
                    if not page_has_valid:
                        break
                    
                    # ìš”ì²­ ê°„ ë”œë ˆì´ ì¶”ê°€ (403 ìš°íšŒ ë° Rate limiting ë°©ì§€)
                    await asyncio.sleep(0.5)
                    
                    page_count += 1
        
        return {
            'count': len(solved_problems),
            'problems': sorted(list(solved_problems))
        }
    except Exception as e:
        print(f"ë°±ì¤€ status í˜ì´ì§€ í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")
        return {'count': 0, 'problems': []}

async def get_recent_solved_count(baekjoon_id: str, start_date: datetime, end_date: datetime) -> int:
    """
    íŠ¹ì • ê¸°ê°„ ë™ì•ˆ í•´ê²°í•œ ë¬¸ì œ ìˆ˜ ê°€ì ¸ì˜¤ê¸°
    
    Args:
        baekjoon_id: ë°±ì¤€ ì•„ì´ë””
        start_date: ì‹œì‘ ë‚ ì§œ (datetime)
        end_date: ì¢…ë£Œ ë‚ ì§œ (datetime)
    
    Returns:
        í•´ê²°í•œ ë¬¸ì œ ìˆ˜
    """
    try:
        # ë°±ì¤€ status í˜ì´ì§€ì—ì„œ ìµœê·¼ ì œì¶œ ë‚´ì—­ í™•ì¸
        # ì—¬ëŸ¬ í˜ì´ì§€ë¥¼ í™•ì¸í•´ì•¼ í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ìµœê·¼ 100ê°œ ì •ë„ í™•ì¸
        solved_problems = set()
        page = 1
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        
        async with aiohttp.ClientSession(headers=headers) as session:
            # ìµœëŒ€ 10í˜ì´ì§€ê¹Œì§€ í™•ì¸ (ìµœê·¼ 1000ê°œ ì œì¶œ)
            for page in range(1, 11):
                url = f"https://www.acmicpc.net/status?user_id={baekjoon_id}&result_id=4&page={page}"
                # result_id=4ëŠ” "ë§ì•˜ìŠµë‹ˆë‹¤" ê²°ê³¼
                
                async with session.get(url) as response:
                    if response.status != 200:
                        break
                    
                    html = await response.text()
                    soup = BeautifulSoup(html, 'html.parser')
                    
                    # status í…Œì´ë¸” ì°¾ê¸°
                    status_table = soup.find('table', id='status-table')
                    if not status_table:
                        break
                    
                    tbody = status_table.find('tbody')
                    if not tbody:
                        break
                    
                    rows = tbody.find_all('tr')
                    if not rows:
                        break
                    
                    # ì´ í˜ì´ì§€ì˜ ëª¨ë“  ì œì¶œì´ ê¸°ê°„ì„ ë²—ì–´ë‚˜ë©´ ì¤‘ë‹¨
                    page_has_valid = False
                    
                    for tr in rows:
                        # ê²°ê³¼ í™•ì¸
                        result_td = tr.find('td', class_='result')
                        if not result_td:
                            continue
                        
                        result_text = result_td.get_text(strip=True)
                        if 'ë§ì•˜ìŠµë‹ˆë‹¤' not in result_text:
                            continue
                        
                        # ì œì¶œ ì‹œê°„ ì°¾ê¸°
                        time_td = tr.find('td', class_='real-time-update')
                        if not time_td:
                            time_elem = tr.find('a', class_='real-time-update')
                            if time_elem and time_elem.get('title'):
                                time_str = time_elem.get('title')
                            else:
                                continue
                        else:
                            time_str = time_td.get_text(strip=True)
                        
                        # ì‹œê°„ íŒŒì‹±
                        try:
                            if '-' in time_str and ':' in time_str:
                                # "2024-01-01 12:34:56" í˜•ì‹
                                submitted_dt = datetime.strptime(time_str, '%Y-%m-%d %H:%M:%S')
                            else:
                                # ìƒëŒ€ ì‹œê°„ì¸ ê²½ìš° í˜„ì¬ ì‹œê°„ ì‚¬ìš© (ì •í™•í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ)
                                continue
                        except:
                            continue
                        
                        # ê¸°ê°„ í™•ì¸
                        if start_date <= submitted_dt <= end_date:
                            # ë¬¸ì œ ë²ˆí˜¸ ì°¾ê¸°
                            problem_link = tr.find('a', href=re.compile(r'/problem/\d+'))
                            if problem_link:
                                match = re.search(r'/problem/(\d+)', problem_link.get('href', ''))
                                if match:
                                    problem_id = int(match.group(1))
                                    solved_problems.add(problem_id)
                                    page_has_valid = True
                    
                    # ì´ í˜ì´ì§€ì— ìœ íš¨í•œ ì œì¶œì´ ì—†ìœ¼ë©´ ë” ì´ìƒ í™•ì¸í•˜ì§€ ì•ŠìŒ
                    if not page_has_valid:
                        break
        
        return len(solved_problems)
    except Exception as e:
        print(f"ìµœê·¼ í•´ê²°í•œ ë¬¸ì œ ìˆ˜ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return 0

async def check_problem_solved_from_status(baekjoon_id: str, problem_id: int) -> Optional[Dict]:
    """
    BOJ status í˜ì´ì§€ì—ì„œ ë¬¸ì œ í•´ê²° ì—¬ë¶€ ë° ì œì¶œ ì‹œê°„ í™•ì¸
    
    Returns:
        {
            'solved': bool,
            'submitted_at': str (ISO format) or None,
            'result': str (ê²°ê³¼: 'ë§ì•˜ìŠµë‹ˆë‹¤!!', 'í‹€ë ¸ìŠµë‹ˆë‹¤', etc.)
        } or None (ì˜¤ë¥˜ ì‹œ)
    """
    try:
        # status í˜ì´ì§€ URL: ë¬¸ì œ ë²ˆí˜¸ì™€ ì‚¬ìš©ì IDë¡œ í•„í„°ë§
        url = f"https://www.acmicpc.net/status?option-status-pid=on&problem_id={problem_id}&user_id={baekjoon_id}&language_id=-1&result_id=-1&from_problem=1"
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        
        async with aiohttp.ClientSession(headers=headers) as session:
            async with session.get(url) as response:
                if response.status != 200:
                    return None
                
                html = await response.text()
                soup = BeautifulSoup(html, 'html.parser')
                
                # status í…Œì´ë¸” ì°¾ê¸°
                status_table = soup.find('table', id='status-table')
                if not status_table:
                    return {'solved': False, 'submitted_at': None, 'result': None}
                
                # í…Œì´ë¸” í–‰ ì°¾ê¸° (ì²« ë²ˆì§¸ í–‰ì´ ê°€ì¥ ìµœê·¼ ì œì¶œ)
                rows = status_table.find('tbody')
                if not rows:
                    return {'solved': False, 'submitted_at': None, 'result': None}
                
                trs = rows.find_all('tr')
                if not trs:
                    return {'solved': False, 'submitted_at': None, 'result': None}
                
                # ê° í–‰ì„ í™•ì¸í•˜ì—¬ ë§ì€ ì œì¶œ ì°¾ê¸°
                for tr in trs:
                    # ê²°ê³¼ í™•ì¸ (ë§ì•˜ìŠµë‹ˆë‹¤!!, ë§ì•˜ìŠµë‹ˆë‹¤, etc.)
                    result_td = tr.find('td', class_='result')
                    if not result_td:
                        continue
                    
                    result_text = result_td.get_text(strip=True)
                    
                    # ë§ì€ ì œì¶œì¸ì§€ í™•ì¸
                    if 'ë§ì•˜ìŠµë‹ˆë‹¤' in result_text or 'ì •ë‹µ' in result_text:
                        # ì œì¶œ ì‹œê°„ ì°¾ê¸°
                        time_td = tr.find('td', class_='real-time-update')
                        if not time_td:
                            # ëŒ€ì²´ ë°©ë²•: title ì†ì„±ì—ì„œ ì‹œê°„ ì°¾ê¸°
                            time_elem = tr.find('a', class_='real-time-update')
                            if time_elem and time_elem.get('title'):
                                time_str = time_elem.get('title')
                            else:
                                time_str = None
                        else:
                            time_str = time_td.get_text(strip=True)
                        
                        # ì‹œê°„ íŒŒì‹± (BOJ í˜•ì‹: "2024-01-01 12:34:56" ë˜ëŠ” ìƒëŒ€ ì‹œê°„)
                        submitted_at = None
                        if time_str:
                            try:
                                # ì ˆëŒ€ ì‹œê°„ í˜•ì‹ì¸ ê²½ìš°
                                if '-' in time_str and ':' in time_str:
                                    # "2024-01-01 12:34:56" í˜•ì‹
                                    submitted_at = datetime.strptime(time_str, '%Y-%m-%d %H:%M:%S').isoformat()
                                else:
                                    # ìƒëŒ€ ì‹œê°„ì¸ ê²½ìš° (ì˜ˆ: "1ë¶„ ì „") í˜„ì¬ ì‹œê°„ ì‚¬ìš©
                                    submitted_at = datetime.now().isoformat()
                            except:
                                submitted_at = datetime.now().isoformat()
                        
                        return {
                            'solved': True,
                            'submitted_at': submitted_at,
                            'result': result_text
                        }
                
                # ë§ì€ ì œì¶œì´ ì—†ìœ¼ë©´ í•´ê²°í•˜ì§€ ì•ŠìŒ
                return {'solved': False, 'submitted_at': None, 'result': None}
                
    except Exception as e:
        print(f"status í˜ì´ì§€ í™•ì¸ ì˜¤ë¥˜: {e}")
        return None

async def check_problems_solved_with_tier(baekjoon_id: str, problem_ids: List[int], min_tier: int = None) -> Dict[int, bool]:
    """ì—¬ëŸ¬ ë¬¸ì œì˜ í•´ê²° ì—¬ë¶€ í™•ì¸ (ë‚œì´ë„ í•„í„°ë§)"""
    solved_problems = await get_user_solved_problems(baekjoon_id)
    result = {}
    
    for problem_id in problem_ids:
        if problem_id in solved_problems:
            if min_tier is not None:
                tier = await get_problem_tier(problem_id)
                if tier is not None and tier >= min_tier:
                    result[problem_id] = True
                else:
                    result[problem_id] = False
            else:
                result[problem_id] = True
        else:
            result[problem_id] = False
    
    return result

# ë°±ì¤€ ë¡œê·¸ì¸ ì •ë³´ (í…ŒìŠ¤íŠ¸ìš© í•˜ë“œì½”ë”©)
BOJ_USERNAME = "beans3142"
BOJ_PASSWORD = "d3783556"

async def login_boj(session: aiohttp.ClientSession, next_url: str = None) -> bool:
    """
    ë°±ì¤€ì— ë¡œê·¸ì¸
    
    Args:
        session: aiohttp ì„¸ì…˜
        next_url: ë¡œê·¸ì¸ í›„ ë¦¬ë‹¤ì´ë ‰íŠ¸í•  URL (ì„ íƒì‚¬í•­)
    
    Returns:
        ë¡œê·¸ì¸ ì„±ê³µ ì—¬ë¶€
    """
    try:
        # ì„¸ì…˜ ì¿ í‚¤ ì™„ì „íˆ ì œê±°
        print(f"[BOJ ë¡œê·¸ì¸] 0ë‹¨ê³„: ì„¸ì…˜ ì¿ í‚¤ ì œê±°")
        session.cookie_jar.clear()
        
        # ë¨¼ì € ë¡œê·¸ì•„ì›ƒ ì‹œë„ (ê¸°ì¡´ ì„¸ì…˜ ì œê±°)
        logout_url = "https://www.acmicpc.net/logout"
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Referer': 'https://www.acmicpc.net/',
        }
        
        print(f"[BOJ ë¡œê·¸ì¸] 0-1ë‹¨ê³„: ë¡œê·¸ì•„ì›ƒ ì‹œë„")
        try:
            async with session.post(logout_url, headers=headers, allow_redirects=True) as response:
                print(f"[BOJ ë¡œê·¸ì¸] ë¡œê·¸ì•„ì›ƒ ì‘ë‹µ: {response.status}")
                # ë¡œê·¸ì•„ì›ƒ í›„ ì¿ í‚¤ ë‹¤ì‹œ ì œê±°
                session.cookie_jar.clear()
        except:
            pass  # ë¡œê·¸ì•„ì›ƒ ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
        
        # ë¡œê·¸ì¸ í˜ì´ì§€ ì ‘ì†í•˜ì—¬ CSRF í† í° ê°€ì ¸ì˜¤ê¸°
        # next_urlì´ ìˆìœ¼ë©´ í•´ë‹¹ URLë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸, ì—†ìœ¼ë©´ ë©”ì¸ í˜ì´ì§€ë¡œ
        if next_url:
            # URL ì¸ì½”ë”©
            from urllib.parse import quote
            encoded_next = quote(next_url.replace('https://www.acmicpc.net', ''), safe='')
            login_url = f"https://www.acmicpc.net/login?next={encoded_next}"
        else:
            login_url = "https://www.acmicpc.net/login?next=%2F"
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'none',
            'Referer': 'https://www.acmicpc.net/'
        }
        
        print(f"[BOJ ë¡œê·¸ì¸] 1ë‹¨ê³„: ë¡œê·¸ì¸ í˜ì´ì§€ ì ‘ì† ì‹œë„")
        print(f"[BOJ ë¡œê·¸ì¸] URL: {login_url}")
        print(f"[BOJ ë¡œê·¸ì¸] ì‚¬ìš©ì: {BOJ_USERNAME}")
        
        # AWS WAF ìš°íšŒë¥¼ ìœ„í•´ ì•½ê°„ì˜ ë”œë ˆì´ ì¶”ê°€
        import asyncio
        await asyncio.sleep(1)
        
        async with session.get(login_url, headers=headers, allow_redirects=True) as response:
            print(f"[BOJ ë¡œê·¸ì¸] 1ë‹¨ê³„ ì‘ë‹µ ìƒíƒœ: {response.status}")
            print(f"[BOJ ë¡œê·¸ì¸] ì‘ë‹µ URL: {str(response.url)}")
            
            html = await response.text()
            
            # AWS WAF ì±Œë¦°ì§€ í˜ì´ì§€ í™•ì¸
            if response.status == 202 or 'awsWafCookieDomainList' in html or 'gokuProps' in html:
                print("[BOJ ë¡œê·¸ì¸] âš ï¸ AWS WAF ì±Œë¦°ì§€ í˜ì´ì§€ ê°ì§€ë¨")
                print(f"[BOJ ë¡œê·¸ì¸] ì‘ë‹µ ë³¸ë¬¸ (ì²˜ìŒ 500ì): {html[:500]}")
                # ì±Œë¦°ì§€ í˜ì´ì§€ì¸ ê²½ìš°, ì¶”ê°€ ëŒ€ê¸° í›„ ì¬ì‹œë„
                print("[BOJ ë¡œê·¸ì¸] 5ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„...")
                await asyncio.sleep(5)
                async with session.get(login_url, headers=headers, allow_redirects=True) as retry_response:
                    print(f"[BOJ ë¡œê·¸ì¸] ì¬ì‹œë„ ì‘ë‹µ ìƒíƒœ: {retry_response.status}")
                    if retry_response.status != 200:
                        print(f"[BOJ ë¡œê·¸ì¸] ë¡œê·¸ì¸ í˜ì´ì§€ ì ‘ì† ì‹¤íŒ¨: HTTP {retry_response.status}")
                        retry_html = await retry_response.text()
                        if 'awsWafCookieDomainList' in retry_html or 'gokuProps' in retry_html:
                            print("[BOJ ë¡œê·¸ì¸] âŒ AWS WAF ì±Œë¦°ì§€ í˜ì´ì§€ê°€ ê³„ì† ë°˜í™˜ë¨")
                        return False
                    html = await retry_response.text()
                    if 'awsWafCookieDomainList' in html or 'gokuProps' in html:
                        print("[BOJ ë¡œê·¸ì¸] âŒ AWS WAF ì±Œë¦°ì§€ í˜ì´ì§€ê°€ ê³„ì† ë°˜í™˜ë¨")
                        return False
            
            if response.status != 200:
                print(f"[BOJ ë¡œê·¸ì¸] ë¡œê·¸ì¸ í˜ì´ì§€ ì ‘ì† ì‹¤íŒ¨: HTTP {response.status}")
                try:
                    print(f"[BOJ ë¡œê·¸ì¸] ì‘ë‹µ ë³¸ë¬¸ (ì²˜ìŒ 500ì): {html[:500]}")
                except:
                    pass
                return False
            
            print(f"[BOJ ë¡œê·¸ì¸] HTML í¬ê¸°: {len(html)} bytes")
            soup = BeautifulSoup(html, 'html.parser')
            
            # ì´ë¯¸ ë¡œê·¸ì¸ëœ ìƒíƒœì¸ì§€ í™•ì¸ (ë¡œê·¸ì•„ì›ƒ ë§í¬ë‚˜ ì‚¬ìš©ì ì •ë³´ í™•ì¸)
            is_already_logged_in = False
            logout_link = soup.find('a', href='/logout')
            logout_form = soup.find('form', {'action': '/logout'})
            
            if logout_link or logout_form:
                print("[BOJ ë¡œê·¸ì¸] âš ï¸ ë¡œê·¸ì•„ì›ƒ ë§í¬/í¼ ë°œê²¬ - ì´ë¯¸ ë¡œê·¸ì¸ëœ ìƒíƒœì¼ ìˆ˜ ìˆìŒ")
                # ì‹¤ì œë¡œ ë¡œê·¸ì¸ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
                if BOJ_USERNAME in html or 'ë¡œê·¸ì•„ì›ƒ' in html or 'logout' in html.lower():
                    print("[BOJ ë¡œê·¸ì¸] âœ… ì‹¤ì œë¡œ ë¡œê·¸ì¸ë˜ì–´ ìˆìŒ - ë¡œê·¸ì¸ ê³¼ì • ìƒëµ")
                    is_already_logged_in = True
                    # ë©”ì¸ í˜ì´ì§€ë¡œ ì´ë™í•˜ì—¬ ìµœì¢… í™•ì¸
                    try:
                        async with session.get("https://www.acmicpc.net/", headers=headers, allow_redirects=True) as test_response:
                            test_html = await test_response.text()
                            if BOJ_USERNAME in test_html or ('ë¡œê·¸ì•„ì›ƒ' in test_html and 'login_user_id' not in test_html):
                                print("[BOJ ë¡œê·¸ì¸] âœ… ë©”ì¸ í˜ì´ì§€ì—ì„œ ë¡œê·¸ì¸ ìƒíƒœ í™•ì¸ë¨")
                                return True
                            else:
                                print("[BOJ ë¡œê·¸ì¸] âš ï¸ ë©”ì¸ í˜ì´ì§€ì—ì„œ ë¡œê·¸ì¸ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨ - ë¡œê·¸ì¸ ì‹œë„")
                                is_already_logged_in = False
                    except:
                        print("[BOJ ë¡œê·¸ì¸] âš ï¸ ë©”ì¸ í˜ì´ì§€ í™•ì¸ ì‹¤íŒ¨ - ë¡œê·¸ì¸ ì‹œë„")
                        is_already_logged_in = False
            
            # ë¡œê·¸ì¸ í¼ ì°¾ê¸°
            login_form = soup.find('form', {'action': '/login'}) or soup.find('form', {'method': 'post'}) or soup.find('form')
            form_action = '/login'  # ê¸°ë³¸ê°’
            form_method = 'post'
            
            if not is_already_logged_in:
                if login_form:
                    form_action = login_form.get('action', '/login')
                    form_method = login_form.get('method', 'post').lower()
                    print(f"[BOJ ë¡œê·¸ì¸] ë¡œê·¸ì¸ í¼ ë°œê²¬: action={form_action}, method={form_method}")
                    
                    # actionì´ ìƒëŒ€ ê²½ë¡œë©´ ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
                    if form_action and not form_action.startswith('http'):
                        if form_action.startswith('/'):
                            form_action = f"https://www.acmicpc.net{form_action}"
                        else:
                            form_action = f"https://www.acmicpc.net/login"
                    
                    # actionì´ /logoutì´ë©´ ë¡œê·¸ì¸ í¼ì´ ì•„ë‹˜
                    if '/logout' in form_action:
                        print("[BOJ ë¡œê·¸ì¸] âš ï¸ ë¡œê·¸ì¸ í¼ì´ ì•„ë‹Œ ê²ƒìœ¼ë¡œ ë³´ì„. ê¸°ë³¸ê°’ ì‚¬ìš©: /login")
                        form_action = "https://www.acmicpc.net/login"
                else:
                    print("[BOJ ë¡œê·¸ì¸] âš ï¸ ë¡œê·¸ì¸ í¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ - ê¸°ë³¸ê°’ ì‚¬ìš©: /login")
                    form_action = "https://www.acmicpc.net/login"
            
            # CSRF í† í° ì°¾ê¸° (ì—¬ëŸ¬ ë°©ë²• ì‹œë„)
            csrf_token = None
            
            # ë°©ë²• 1: name='csrf_key'ì¸ input ì°¾ê¸°
            csrf_input = soup.find('input', {'name': 'csrf_key'})
            if csrf_input:
                csrf_token = csrf_input.get('value')
                if csrf_token:
                    print(f"[BOJ ë¡œê·¸ì¸] CSRF í† í° ì°¾ìŒ (ë°©ë²•1): {csrf_token[:30]}... (ì „ì²´ ê¸¸ì´: {len(csrf_token)})")
            
            # ë°©ë²• 2: name='csrf_token'ì¸ input ì°¾ê¸°
            if not csrf_token:
                csrf_input = soup.find('input', {'name': 'csrf_token'})
                if csrf_input:
                    csrf_token = csrf_input.get('value')
                    if csrf_token:
                        print(f"[BOJ ë¡œê·¸ì¸] CSRF í† í° ì°¾ìŒ (ë°©ë²•2): {csrf_token[:30]}... (ì „ì²´ ê¸¸ì´: {len(csrf_token)})")
            
            # ë°©ë²• 3: meta íƒœê·¸ì—ì„œ ì°¾ê¸°
            if not csrf_token:
                csrf_meta = soup.find('meta', {'name': 'csrf-token'})
                if csrf_meta:
                    csrf_token = csrf_meta.get('content')
                    if csrf_token:
                        print(f"[BOJ ë¡œê·¸ì¸] CSRF í† í° ì°¾ìŒ (ë°©ë²•3): {csrf_token[:30]}... (ì „ì²´ ê¸¸ì´: {len(csrf_token)})")
            
            # ë°©ë²• 4: JavaScriptì—ì„œ ì°¾ê¸° (ì¼ë¶€ ì‚¬ì´íŠ¸ëŠ” JSë¡œ ë™ì  ìƒì„±)
            if not csrf_token:
                scripts = soup.find_all('script')
                for script in scripts:
                    script_text = script.string or ''
                    # csrf ê´€ë ¨ ë³€ìˆ˜ ì°¾ê¸°
                    import re
                    csrf_match = re.search(r'csrf[_-]?token["\']?\s*[:=]\s*["\']([^"\']+)["\']', script_text, re.IGNORECASE)
                    if csrf_match:
                        csrf_token = csrf_match.group(1)
                        print(f"[BOJ ë¡œê·¸ì¸] CSRF í† í° ì°¾ìŒ (ë°©ë²•4-JS): {csrf_token[:30]}... (ì „ì²´ ê¸¸ì´: {len(csrf_token)})")
                        break
            
            if not csrf_token:
                print("[BOJ ë¡œê·¸ì¸] âš ï¸ CSRF í† í°ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ - CSRF í† í° ì—†ì´ ì‹œë„")
                # ëª¨ë“  input íƒœê·¸ ì°¾ê¸°
                inputs = soup.find_all('input')
                print(f"[BOJ ë¡œê·¸ì¸] ë°œê²¬ëœ input íƒœê·¸ ê°œìˆ˜: {len(inputs)}")
                for inp in inputs:
                    name = inp.get('name', '')
                    if 'csrf' in name.lower() or 'token' in name.lower():
                        print(f"[BOJ ë¡œê·¸ì¸]   - name={name}, type={inp.get('type')}, value={inp.get('value', '')[:50]}")
                # CSRF í† í° ì—†ì´ë„ ì‹œë„ (ì¼ë¶€ ì‚¬ì´íŠ¸ëŠ” ì„ íƒì ì¼ ìˆ˜ ìˆìŒ)
                csrf_token = ''  # ë¹ˆ ë¬¸ìì—´ë¡œ ì„¤ì •
        
        # ì´ë¯¸ ë¡œê·¸ì¸ë˜ì–´ ìˆìœ¼ë©´ POST ìš”ì²­ ìƒëµ
        if 'is_already_logged_in' in locals() and is_already_logged_in:
            print("[BOJ ë¡œê·¸ì¸] âœ… ì´ë¯¸ ë¡œê·¸ì¸ë˜ì–´ ìˆìŒ - POST ìš”ì²­ ìƒëµ")
            return True
        
        # ë¡œê·¸ì¸ POST ìš”ì²­
        # CSRF í† í°ì´ ìˆìœ¼ë©´ í¬í•¨, ì—†ìœ¼ë©´ ì œì™¸
        if next_url:
            # next_urlì´ ìˆìœ¼ë©´ í•´ë‹¹ ê²½ë¡œë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸
            next_path = next_url.replace('https://www.acmicpc.net', '')
            login_data = {
                'login_user_id': BOJ_USERNAME,
                'login_password': BOJ_PASSWORD,
                'next': next_path
            }
        else:
            login_data = {
                'login_user_id': BOJ_USERNAME,
                'login_password': BOJ_PASSWORD,
                'next': '/'  # ë¡œê·¸ì¸ í›„ ë¦¬ë‹¤ì´ë ‰íŠ¸í•  ê²½ë¡œ
            }
        
        if csrf_token:
            login_data['csrf_key'] = csrf_token
        
        print(f"[BOJ ë¡œê·¸ì¸] 2ë‹¨ê³„: ë¡œê·¸ì¸ POST ìš”ì²­ ì‹œë„")
        print(f"[BOJ ë¡œê·¸ì¸] POST ë°ì´í„° í‚¤: {list(login_data.keys())}")
        print(f"[BOJ ë¡œê·¸ì¸] ì‚¬ìš©ì ID ê¸¸ì´: {len(BOJ_USERNAME)}")
        print(f"[BOJ ë¡œê·¸ì¸] ë¹„ë°€ë²ˆí˜¸ ê¸¸ì´: {len(BOJ_PASSWORD)}")
        
        # POST ìš”ì²­ í—¤ë” ì¶”ê°€
        post_headers = headers.copy()
        post_headers.update({
            'Content-Type': 'application/x-www-form-urlencoded',
            'Referer': login_url,
            'Origin': 'https://www.acmicpc.net',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'same-origin'
        })
        
        # ì‹¤ì œ ë¡œê·¸ì¸ POST URL ì‚¬ìš© (í¼ì˜ action)
        post_url = form_action if 'form_action' in locals() and form_action else login_url
        print(f"[BOJ ë¡œê·¸ì¸] POST ìš”ì²­ URL: {post_url}")
        
        async with session.post(post_url, data=login_data, headers=post_headers, allow_redirects=True) as response:
            print(f"[BOJ ë¡œê·¸ì¸] 2ë‹¨ê³„ ì‘ë‹µ ìƒíƒœ: {response.status}")
            print(f"[BOJ ë¡œê·¸ì¸] ì‘ë‹µ URL: {str(response.url)}")
            
            # ì‘ë‹µ í—¤ë” í™•ì¸
            location = response.headers.get('Location', '')
            set_cookie = response.headers.get('Set-Cookie', '')
            if location:
                print(f"[BOJ ë¡œê·¸ì¸] ë¦¬ë‹¤ì´ë ‰íŠ¸ ìœ„ì¹˜: {location}")
            if set_cookie:
                print(f"[BOJ ë¡œê·¸ì¸] Set-Cookie í—¤ë” ë°œê²¬ (ê¸¸ì´: {len(set_cookie)})")
            
            # ì‘ë‹µ ë³¸ë¬¸ í™•ì¸ (ì—ëŸ¬ ë©”ì‹œì§€ê°€ ìˆì„ ìˆ˜ ìˆìŒ)
            response_text = ""
            try:
                response_text = await response.text()
                if len(response_text) < 2000:  # ì§§ì€ ì‘ë‹µë§Œ ì¶œë ¥
                    print(f"[BOJ ë¡œê·¸ì¸] ì‘ë‹µ ë³¸ë¬¸: {response_text}")
                else:
                    print(f"[BOJ ë¡œê·¸ì¸] ì‘ë‹µ ë³¸ë¬¸ (ì²˜ìŒ 1000ì): {response_text[:1000]}")
                    # ì—ëŸ¬ ë©”ì‹œì§€ ì°¾ê¸°
                    if 'error' in response_text.lower() or 'ì‹¤íŒ¨' in response_text or 'í‹€ë ¸' in response_text or 'ì˜ëª»' in response_text:
                        print(f"[BOJ ë¡œê·¸ì¸] âš ï¸ ì—ëŸ¬ ë©”ì‹œì§€ê°€ ì‘ë‹µì— í¬í•¨ë˜ì–´ ìˆìŒ")
            except Exception as e:
                print(f"[BOJ ë¡œê·¸ì¸] ì‘ë‹µ ë³¸ë¬¸ ì½ê¸° ì‹¤íŒ¨: {e}")
            
            # ë¡œê·¸ì¸ ì„±ê³µ ì—¬ë¶€ íŒë‹¨
            # 1. ë¦¬ë‹¤ì´ë ‰íŠ¸ í™•ì¸ (302ëŠ” ì„±ê³µ)
            # 2. ì‘ë‹µ ë³¸ë¬¸ì— ë¡œê·¸ì¸ í¼ì´ ì—†ìœ¼ë©´ ì„±ê³µ (ë¡œê·¸ì¸ í˜ì´ì§€ê°€ ì•„ë‹ˆë©´)
            # 3. ì¿ í‚¤ í™•ì¸
            # 4. ì‹¤ì œ ë¡œê·¸ì¸ í™•ì¸ (ë©”ì¸ í˜ì´ì§€ ì ‘ì† í…ŒìŠ¤íŠ¸)
            success = False
            
            if response.status == 302:
                print(f"[BOJ ë¡œê·¸ì¸] âœ… ë¡œê·¸ì¸ ì„±ê³µ (ë¦¬ë‹¤ì´ë ‰íŠ¸: {response.status})")
                success = True
            elif response.status == 200:
                # ì‘ë‹µ ë³¸ë¬¸ ë¶„ì„
                if response_text:
                    # ë¡œê·¸ì¸ í¼ì´ ìˆìœ¼ë©´ ì‹¤íŒ¨, ì—†ìœ¼ë©´ ì„±ê³µ
                    has_login_form = 'login_user_id' in response_text or 'login_password' in response_text or '<title>ë¡œê·¸ì¸</title>' in response_text
                    has_logout_form = 'action="/logout"' in response_text or 'action=\'/logout\'' in response_text
                    
                    if has_logout_form and not has_login_form:
                        print(f"[BOJ ë¡œê·¸ì¸] âœ… ë¡œê·¸ì¸ ì„±ê³µ (ë¡œê·¸ì•„ì›ƒ í¼ ë°œê²¬ - ì´ë¯¸ ë¡œê·¸ì¸ë¨)")
                        success = True
                    elif not has_login_form:
                        print(f"[BOJ ë¡œê·¸ì¸] âœ… ë¡œê·¸ì¸ ì„±ê³µ (ë¡œê·¸ì¸ í¼ ì—†ìŒ)")
                        success = True
                    else:
                        print(f"[BOJ ë¡œê·¸ì¸] âŒ ë¡œê·¸ì¸ ì‹¤íŒ¨ (ë¡œê·¸ì¸ í¼ì´ ì—¬ì „íˆ ìˆìŒ)")
                        success = False
                else:
                    # ì‘ë‹µ ë³¸ë¬¸ì´ ì—†ìœ¼ë©´ ìƒíƒœ ì½”ë“œë§Œìœ¼ë¡œ íŒë‹¨
                    print(f"[BOJ ë¡œê·¸ì¸] âš ï¸ ì‘ë‹µ ë³¸ë¬¸ ì—†ìŒ, ìƒíƒœ ì½”ë“œë¡œë§Œ íŒë‹¨: {response.status}")
                    success = False
            
            # ì¿ í‚¤ í™•ì¸
            cookies = session.cookie_jar
            cookie_count = len(list(cookies))
            print(f"[BOJ ë¡œê·¸ì¸] ì„¸ì…˜ ì¿ í‚¤ ê°œìˆ˜: {cookie_count}")
            if cookie_count > 0:
                print(f"[BOJ ë¡œê·¸ì¸] ì¿ í‚¤ê°€ ì„¤ì •ë¨ (ë¡œê·¸ì¸ ì„±ê³µ ê°€ëŠ¥ì„± ë†’ìŒ)")
            
            # ì‹¤ì œ ë¡œê·¸ì¸ í™•ì¸ (ë©”ì¸ í˜ì´ì§€ ì ‘ì† í…ŒìŠ¤íŠ¸)
            if success or cookie_count > 0:
                print(f"[BOJ ë¡œê·¸ì¸] ë¡œê·¸ì¸ í™•ì¸ì„ ìœ„í•´ ë©”ì¸ í˜ì´ì§€ ì ‘ì† í…ŒìŠ¤íŠ¸...")
                try:
                    test_headers = headers.copy()
                    test_headers['Referer'] = 'https://www.acmicpc.net/login'
                    async with session.get("https://www.acmicpc.net/", headers=test_headers, allow_redirects=True) as test_response:
                        test_html = await test_response.text()
                        test_url = str(test_response.url)
                        print(f"[BOJ ë¡œê·¸ì¸] ë©”ì¸ í˜ì´ì§€ ì‘ë‹µ URL: {test_url}")
                        
                        # ë¡œê·¸ì¸ëœ ìƒíƒœë©´ ì‚¬ìš©ì ì •ë³´ê°€ ìˆìŒ
                        has_username = BOJ_USERNAME in test_html
                        has_logout = 'ë¡œê·¸ì•„ì›ƒ' in test_html or 'logout' in test_html.lower()
                        has_login_form = 'login_user_id' in test_html or '<title>ë¡œê·¸ì¸</title>' in test_html
                        
                        print(f"[BOJ ë¡œê·¸ì¸] ë©”ì¸ í˜ì´ì§€ ë¶„ì„: ì‚¬ìš©ìëª…={has_username}, ë¡œê·¸ì•„ì›ƒ={has_logout}, ë¡œê·¸ì¸í¼={has_login_form}")
                        
                        if (has_username or has_logout) and not has_login_form:
                            print(f"[BOJ ë¡œê·¸ì¸] âœ… ì‹¤ì œ ë¡œê·¸ì¸ í™•ì¸ë¨ (ë©”ì¸ í˜ì´ì§€ì—ì„œ ì‚¬ìš©ì ì •ë³´ ë°œê²¬)")
                            success = True
                        elif has_login_form:
                            print(f"[BOJ ë¡œê·¸ì¸] âŒ ì‹¤ì œ ë¡œê·¸ì¸ ì‹¤íŒ¨ (ë©”ì¸ í˜ì´ì§€ì— ë¡œê·¸ì¸ í¼ ë°œê²¬)")
                            success = False
                        else:
                            print(f"[BOJ ë¡œê·¸ì¸] âš ï¸ ë¡œê·¸ì¸ ìƒíƒœ ë¶ˆëª…í™•")
                except Exception as e:
                    print(f"[BOJ ë¡œê·¸ì¸] ë¡œê·¸ì¸ í™•ì¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
                    import traceback
                    traceback.print_exc()
            
            if success:
                print(f"[BOJ ë¡œê·¸ì¸] âœ… ìµœì¢… íŒë‹¨: ë¡œê·¸ì¸ ì„±ê³µ")
            else:
                print(f"[BOJ ë¡œê·¸ì¸] âŒ ìµœì¢… íŒë‹¨: ë¡œê·¸ì¸ ì‹¤íŒ¨")
            return success
    
    except Exception as e:
        print(f"[BOJ ë¡œê·¸ì¸] âŒ ì˜ˆì™¸ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return False

async def get_group_practice_ranking(practice_url: str) -> Dict[str, int]:
    """
    ê·¸ë£¹ ì—°ìŠµ ì„¸ì…˜ ë­í‚¹ì—ì„œ ì‚¬ìš©ìë³„ í•´ê²°í•œ ë¬¸ì œ ìˆ˜ ê°€ì ¸ì˜¤ê¸°
    
    Args:
        practice_url: ì—°ìŠµ ì„¸ì…˜ URL (ì˜ˆ: https://www.acmicpc.net/group/practice/view/9883/122)
    
    Returns:
        {ì‚¬ìš©ìID: í•´ê²°í•œ ë¬¸ì œ ìˆ˜} ë”•ì…”ë„ˆë¦¬
    """
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        
        print(f"[ë­í‚¹ í¬ë¡¤ë§] ì—°ìŠµ ì„¸ì…˜ URL: {practice_url}")
        async with aiohttp.ClientSession(headers=headers) as session:
            # ë¨¼ì € ì—°ìŠµ ì„¸ì…˜ í˜ì´ì§€ë¡œ ì ‘ì† ì‹œë„ (ë¡œê·¸ì¸ì´ í•„ìš”í•˜ë©´ ìë™ìœ¼ë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸ë¨)
            print(f"[ë­í‚¹ í¬ë¡¤ë§] ì—°ìŠµ ì„¸ì…˜ í˜ì´ì§€ë¡œ ë¨¼ì € ì ‘ì† ì‹œë„: {practice_url}")
            async with session.get(practice_url, headers=headers, allow_redirects=True) as initial_response:
                print(f"[ë­í‚¹ í¬ë¡¤ë§] ì´ˆê¸° ì ‘ì† ì‘ë‹µ: {initial_response.status}")
                print(f"[ë­í‚¹ í¬ë¡¤ë§] ì´ˆê¸° ì ‘ì† ìµœì¢… URL: {str(initial_response.url)}")
                
                initial_html = await initial_response.text()
                
                # ë¡œê·¸ì¸ì´ í•„ìš”í•œì§€ í™•ì¸
                if 'ë¡œê·¸ì¸' in initial_html and 'login_user_id' in initial_html:
                    print("[ë­í‚¹ í¬ë¡¤ë§] ë¡œê·¸ì¸ì´ í•„ìš”í•¨ - ë¡œê·¸ì¸ ì‹œë„...")
                    # ë¡œê·¸ì¸ ì‹œ next íŒŒë¼ë¯¸í„°ë¥¼ ì—°ìŠµ ì„¸ì…˜ URLë¡œ ì„¤ì •
                    login_success = await login_boj(session, next_url=practice_url)
                    if not login_success:
                        print("[ë­í‚¹ í¬ë¡¤ë§] ë°±ì¤€ ë¡œê·¸ì¸ ì‹¤íŒ¨")
                        return {}
                    print("[ë­í‚¹ í¬ë¡¤ë§] ë¡œê·¸ì¸ ì„±ê³µ - ì—°ìŠµ ì„¸ì…˜ í˜ì´ì§€ë¡œ ë‹¤ì‹œ ì ‘ì†")
                else:
                    print("[ë­í‚¹ í¬ë¡¤ë§] ì´ë¯¸ ë¡œê·¸ì¸ë˜ì–´ ìˆê±°ë‚˜ ë¡œê·¸ì¸ ë¶ˆí•„ìš”")
                    # ì´ë¯¸ ì ‘ê·¼ ê°€ëŠ¥í•œ ê²½ìš°
                    if 'contest_scoreboard' in initial_html:
                        print("[ë­í‚¹ í¬ë¡¤ë§] ë­í‚¹ í…Œì´ë¸”ì´ ì´ë¯¸ ë¡œë“œë¨")
                        # ë°”ë¡œ íŒŒì‹± ì§„í–‰
                        soup = BeautifulSoup(initial_html, 'html.parser')
                        ranking_table = soup.find('table', id='contest_scoreboard')
                        if ranking_table:
                            # íŒŒì‹± ë¡œì§ìœ¼ë¡œ ì´ë™ (ì•„ë˜ ì½”ë“œ ì¬ì‚¬ìš©)
                            pass
                        else:
                            # ë¡œê·¸ì¸ í•„ìš”í•  ìˆ˜ ìˆìŒ
                            print("[ë­í‚¹ í¬ë¡¤ë§] ë¡œê·¸ì¸ ì‹œë„...")
                            login_success = await login_boj(session, next_url=practice_url)
                            if not login_success:
                                print("[ë­í‚¹ í¬ë¡¤ë§] ë°±ì¤€ ë¡œê·¸ì¸ ì‹¤íŒ¨")
                                return {}
                            print("[ë­í‚¹ í¬ë¡¤ë§] ë¡œê·¸ì¸ ì„±ê³µ")
            
            # ì—°ìŠµ ì„¸ì…˜ í˜ì´ì§€ ì ‘ì† (ë¡œê·¸ì¸ í›„ ìë™ ë¦¬ë‹¤ì´ë ‰íŠ¸ë¨)
            print(f"[ë­í‚¹ í¬ë¡¤ë§] ì—°ìŠµ ì„¸ì…˜ í˜ì´ì§€ ì ‘ì† ì‹œë„: {practice_url}")
            
            page_headers = headers.copy()
            page_headers['Referer'] = 'https://www.acmicpc.net/'
            page_headers['Accept'] = 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8'
            page_headers['Accept-Language'] = 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7'
            
            async with session.get(practice_url, headers=page_headers, allow_redirects=True) as response:
                print(f"[ë­í‚¹ í¬ë¡¤ë§] í˜ì´ì§€ ì‘ë‹µ: {response.status}")
                print(f"[ë­í‚¹ í¬ë¡¤ë§] ì‘ë‹µ URL: {str(response.url)}")
                
                # ë¦¬ë‹¤ì´ë ‰íŠ¸ ì²˜ë¦¬
                if response.status in [301, 302, 303, 307, 308]:
                    location = response.headers.get('Location', '')
                    print(f"[ë­í‚¹ í¬ë¡¤ë§] ë¦¬ë‹¤ì´ë ‰íŠ¸ ê°ì§€: {location}")
                    if location and '/login' in location:
                        print("[ë­í‚¹ í¬ë¡¤ë§] âš ï¸ ë¡œê·¸ì¸ í˜ì´ì§€ë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸ë¨ - ê¶Œí•œ ë¬¸ì œ ë˜ëŠ” ì¿ í‚¤ ë¬¸ì œ")
                        # ë¦¬ë‹¤ì´ë ‰íŠ¸ëœ í˜ì´ì§€ í™•ì¸
                        if location.startswith('/'):
                            location = f"https://www.acmicpc.net{location}"
                        async with session.get(location, headers=page_headers, allow_redirects=True) as redirect_response:
                            redirect_html = await redirect_response.text()
                            print(f"[ë­í‚¹ í¬ë¡¤ë§] ë¦¬ë‹¤ì´ë ‰íŠ¸ í›„ ìµœì¢… URL: {str(redirect_response.url)}")
                            if 'ë¡œê·¸ì¸' in redirect_html and 'login_user_id' in redirect_html:
                                print("[ë­í‚¹ í¬ë¡¤ë§] âŒ ë¡œê·¸ì¸ í˜ì´ì§€ë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸ë¨ - ì¿ í‚¤ê°€ ì „ë‹¬ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ê¶Œí•œì´ ì—†ìŒ")
                                return {}
                            html = redirect_html
                    else:
                        # ë‹¤ë¥¸ ë¦¬ë‹¤ì´ë ‰íŠ¸ì¸ ê²½ìš° ë”°ë¼ê°€ê¸°
                        if location.startswith('/'):
                            location = f"https://www.acmicpc.net{location}"
                        async with session.get(location, headers=page_headers, allow_redirects=True) as redirect_response:
                            response = redirect_response
                            html = await response.text()
                else:
                    html = await response.text()
                
                print(f"[ë­í‚¹ í¬ë¡¤ë§] HTML í¬ê¸°: {len(html)} bytes")
                soup = BeautifulSoup(html, 'html.parser')
                
                # ë¡œê·¸ì¸ í•„ìš” ì—¬ë¶€ í™•ì¸
                if 'ë¡œê·¸ì¸' in html and 'login_user_id' in html:
                    print("[ë­í‚¹ í¬ë¡¤ë§] âš ï¸ ë¡œê·¸ì¸ì´ í•„ìš”í•œ í˜ì´ì§€ë¡œ ë³´ì„ - ì¿ í‚¤ê°€ ì „ë‹¬ë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŒ")
                    print(f"[ë­í‚¹ í¬ë¡¤ë§] HTML ì¼ë¶€ (ì²˜ìŒ 2000ì): {html[:2000]}")
                    # ì¿ í‚¤ ì¬í™•ì¸
                    cookies_after = list(session.cookie_jar)
                    print(f"[ë­í‚¹ í¬ë¡¤ë§] ìš”ì²­ í›„ ì¿ í‚¤ ê°œìˆ˜: {len(cookies_after)}")
                    return {}
                
                # ë­í‚¹ í…Œì´ë¸” ì°¾ê¸° (ì—¬ëŸ¬ ë°©ë²• ì‹œë„)
                ranking_table = None
                
                # ë°©ë²• 1: id="contest_scoreboard"ë¡œ ì°¾ê¸° (ê°€ì¥ í™•ì‹¤í•œ ë°©ë²•)
                ranking_table = soup.find('table', id='contest_scoreboard')
                if ranking_table:
                    print("[ë­í‚¹ í¬ë¡¤ë§] ë­í‚¹ í…Œì´ë¸” ì°¾ìŒ (id=contest_scoreboard)")
                else:
                    # ë°©ë²• 2: classì— tableì´ ìˆëŠ” table íƒœê·¸ ì°¾ê¸°
                    ranking_table = soup.find('table', class_=re.compile(r'table', re.I))
                    if ranking_table:
                        print("[ë­í‚¹ í¬ë¡¤ë§] ë­í‚¹ í…Œì´ë¸” ì°¾ìŒ (classë¡œ)")
                
                if not ranking_table:
                    # ë°©ë²• 3: ëª¨ë“  table íƒœê·¸ ì°¾ê¸°
                    tables = soup.find_all('table')
                    print(f"[ë­í‚¹ í¬ë¡¤ë§] ë°œê²¬ëœ table íƒœê·¸ ê°œìˆ˜: {len(tables)}")
                    
                    for i, table in enumerate(tables):
                        # tbodyê°€ ìˆê³ , ì—¬ëŸ¬ í–‰ì´ ìˆëŠ” í…Œì´ë¸” ì°¾ê¸°
                        tbody = table.find('tbody')
                        if tbody:
                            rows = tbody.find_all('tr')
                            print(f"[ë­í‚¹ í¬ë¡¤ë§] í…Œì´ë¸” {i+1}: tbody í–‰ ê°œìˆ˜ = {len(rows)}")
                            if len(rows) > 0:
                                # ì²« ë²ˆì§¸ í–‰ì˜ ì—´ ê°œìˆ˜ í™•ì¸
                                first_row = rows[0]
                                cols = first_row.find_all(['td', 'th'])
                                print(f"[ë­í‚¹ í¬ë¡¤ë§] í…Œì´ë¸” {i+1}: ì²« ë²ˆì§¸ í–‰ ì—´ ê°œìˆ˜ = {len(cols)}")
                                if len(cols) >= 2:  # ìµœì†Œ 2ê°œ ì—´ (ë­í‚¹, ì•„ì´ë””)
                                    ranking_table = table
                                    print(f"[ë­í‚¹ í¬ë¡¤ë§] ë­í‚¹ í…Œì´ë¸” ì°¾ìŒ (í…Œì´ë¸” {i+1})")
                                    break
                
                if not ranking_table:
                    print("[ë­í‚¹ í¬ë¡¤ë§] âŒ ë­í‚¹ í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                    # HTML êµ¬ì¡° í™•ì¸
                    # contest_scoreboard ê²€ìƒ‰
                    if 'contest_scoreboard' in html:
                        print("[ë­í‚¹ í¬ë¡¤ë§] âš ï¸ 'contest_scoreboard' ë¬¸ìì—´ì€ HTMLì— ìˆì§€ë§Œ í…Œì´ë¸”ì„ ì°¾ì§€ ëª»í•¨")
                    # table-responsive div ì°¾ê¸°
                    table_responsive = soup.find('div', class_='table-responsive')
                    if table_responsive:
                        print("[ë­í‚¹ í¬ë¡¤ë§] table-responsive div ë°œê²¬")
                        tables_in_div = table_responsive.find_all('table')
                        print(f"[ë­í‚¹ í¬ë¡¤ë§] table-responsive ë‚´ë¶€ í…Œì´ë¸” ê°œìˆ˜: {len(tables_in_div)}")
                        if tables_in_div:
                            ranking_table = tables_in_div[0]
                            print("[ë­í‚¹ í¬ë¡¤ë§] table-responsive ë‚´ë¶€ì˜ ì²« ë²ˆì§¸ í…Œì´ë¸” ì‚¬ìš©")
                    
                    if not ranking_table:
                        print(f"[ë­í‚¹ í¬ë¡¤ë§] HTML ì¼ë¶€ (ì¤‘ê°„ 2000ì): {html[len(html)//2:len(html)//2+2000]}")
                        # ëª¨ë“  div í™•ì¸
                        divs = soup.find_all('div', class_=re.compile(r'table|rank|list|practice', re.I))
                        print(f"[ë­í‚¹ í¬ë¡¤ë§] ê´€ë ¨ div ê°œìˆ˜: {len(divs)}")
                        return {}
                
                print("[ë­í‚¹ í¬ë¡¤ë§] ë­í‚¹ í…Œì´ë¸” ì°¾ìŒ")
                
                # í…Œì´ë¸” í–‰ íŒŒì‹±
                result = {}
                rows = ranking_table.find('tbody')
                if rows:
                    trs = rows.find_all('tr')
                    print(f"[ë­í‚¹ í¬ë¡¤ë§] í…Œì´ë¸” í–‰ ê°œìˆ˜: {len(trs)}")
                    for tr in trs:
                        # thì™€ td ëª¨ë‘ ì°¾ê¸° (ë°±ì¤€ì€ thë¥¼ ì‚¬ìš©í•¨)
                        cells = tr.find_all(['th', 'td'])
                        if len(cells) < 2:
                            continue
                        
                        # ì•„ì´ë”” ì°¾ê¸° (ë³´í†µ 2ë²ˆì§¸ ì—´, th íƒœê·¸ ì‚¬ìš©)
                        user_id = None
                        # ì²« ë²ˆì§¸ ì—´ì€ ë­í‚¹, ë‘ ë²ˆì§¸ ì—´ì€ ì•„ì´ë””
                        if len(cells) >= 2:
                            user_id_cell = cells[1]
                            # ë§í¬ê°€ ìˆìœ¼ë©´ ë§í¬ í…ìŠ¤íŠ¸, ì—†ìœ¼ë©´ ì…€ í…ìŠ¤íŠ¸
                            link = user_id_cell.find('a')
                            if link:
                                user_id = link.get_text(strip=True)
                                # ì´ë¯¸ì§€ íƒœê·¸ ì œê±°
                                user_id = re.sub(r'<img[^>]*>', '', user_id).strip()
                            else:
                                user_id = user_id_cell.get_text(strip=True)
                        
                        if not user_id:
                            continue
                        
                        # í•´ê²°í•œ ë¬¸ì œ ìˆ˜ ê³„ì‚° (ë§ˆì§€ë§‰ ì—´ì˜ ìˆ«ì)
                        # í˜•ì‹: "2 / 2868" ë˜ëŠ” "2&nbsp;/&nbsp;2868" -> 2ë¥¼ ì¶”ì¶œ (ì´ í•´ê²°í•œ ë¬¸ì œ ìˆ˜)
                        solved_count = 0
                        
                        # ë§ˆì§€ë§‰ ì—´ í™•ì¸ (th ë˜ëŠ” td)
                        last_cell = cells[-1]
                        last_cell_text = last_cell.get_text(strip=True)
                        # &nbsp; ì œê±°
                        last_cell_text = last_cell_text.replace('\xa0', ' ').replace('&nbsp;', ' ')
                        match = re.match(r'(\d+)\s*/\s*\d+', last_cell_text)
                        if match:
                            solved_count = int(match.group(1))
                        else:
                            print(f"[ë­í‚¹ í¬ë¡¤ë§] âš ï¸ ë§ˆì§€ë§‰ ì—´ íŒŒì‹± ì‹¤íŒ¨: '{last_cell_text}'")
                        
                        result[user_id] = solved_count
                        print(f"[ë­í‚¹ í¬ë¡¤ë§] ìœ ì € íŒŒì‹±: {user_id} = {solved_count}ê°œ")
                
                print(f"[ë­í‚¹ í¬ë¡¤ë§] ì´ {len(result)}ëª…ì˜ ìœ ì € ë°ì´í„° íŒŒì‹± ì™„ë£Œ")
                return result
    
    except Exception as e:
        print(f"[ë­í‚¹ í¬ë¡¤ë§] ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return {}

